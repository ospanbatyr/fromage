{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305a9d84-b6ef-4f9f-9602-d0312a70cef7",
   "metadata": {},
   "source": [
    "# Tutorial & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b1a639-9a6b-4695-ab72-417a8b448e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/oince22/.conda/envs/fromage/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fromage.vqa_dataset import VQA_RADDataset\n",
    "from fromage.model import Fromage, FromageModel\n",
    "from fromage.experiment import Experiment\n",
    "from fromage.data import MIMICDataset, cxr_image_transform\n",
    "from fromage.utils import preprocess_report\n",
    "from evaluate import load # if throws error, please run the following command \"pip instal evaluate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2701cd4-9352-41d9-abc5-5a4467d9e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "ckpt_path = \"../logs/checkpoints/lm_med_vis_med/last.ckpt\"\n",
    "config_path = \"../config/train-untied_lm_med_vis_med.yaml\"\n",
    "dataset_path = \"../data/datasets/VQA_RAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498bf455-f4f9-442e-a9fe-b693037ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = cxr_image_transform(resize=512, center_crop_size=480, train=False) \n",
    "dataset = VQA_RADDataset(dataset_path, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfcacef-05b2-4d95-b943-589c5b5b6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0667, 0.0667, 0.0667,  ..., 0.1882, 0.1725, 0.1412],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2039, 0.1961, 0.2000],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2235, 0.2157, 0.2235],\n",
       "          ...,\n",
       "          [0.0784, 0.0706, 0.0706,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0784, 0.0902]],\n",
       " \n",
       "         [[0.0667, 0.0667, 0.0667,  ..., 0.1882, 0.1725, 0.1412],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2039, 0.1961, 0.2000],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2235, 0.2157, 0.2235],\n",
       "          ...,\n",
       "          [0.0784, 0.0706, 0.0706,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0784, 0.0902]],\n",
       " \n",
       "         [[0.0667, 0.0667, 0.0667,  ..., 0.1882, 0.1725, 0.1412],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2039, 0.1961, 0.2000],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2235, 0.2157, 0.2235],\n",
       "          ...,\n",
       "          [0.0784, 0.0706, 0.0706,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0784, 0.0902]]]),\n",
       " 'Are the lungs normal appearing?',\n",
       " 'No')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # returns image, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5d60bf-809b-4230-810e-becc96bb2bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/oince22/.conda/envs/fromage/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/kuacc/users/oince22/.conda/envs/fromage/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/kuacc/users/oince22/.conda/envs/fromage/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/kuacc/users/oince22/.conda/envs/fromage/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "with open(config_path) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "model = Experiment(config)\n",
    "model = model.load_from_checkpoint(ckpt_path)\n",
    "model = model.model.to(\"cuda\")\n",
    "model.device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba751d9f-a501-4906-bf43-b0328e8c4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  Question: Are the lungs normal appearing? Answer (yes or no): \n",
      " Chronic bronchitis. Aortic valve. Left ventricular failure. Right ventricular failure. Left ventricular failure. Left ventricular failure. Left vent\n",
      "bsz: 1, seq_len: 17, dim: 768\n",
      "logits.shape: torch.Size([1, 50267])\n",
      "probs.shape: torch.Size([1, 50267])\n",
      "cur_tok_prob.shape: torch.Size([1, 1])\n",
      "curr_ppl: tensor([[8640.8291]], device='cuda:0')\n",
      "min_ppl: tensor([[8640.8291]], device='cuda:0')\n",
      "bsz: 1, seq_len: 17, dim: 768\n",
      "logits.shape: torch.Size([1, 50267])\n",
      "probs.shape: torch.Size([1, 50267])\n",
      "cur_tok_prob.shape: torch.Size([1, 1])\n",
      "curr_ppl: tensor([[293477.9062]], device='cuda:0')\n",
      "min_ppl: tensor([[293477.9062]], device='cuda:0')\n",
      "Model Answer:  yes\n",
      "Correct Answer:  No\n"
     ]
    }
   ],
   "source": [
    "img, question, answer = dataset[0]\n",
    "prompt = str(\"Question: \" + question + \" Answer (yes or no): \")\n",
    "print(\"Prompt: \", prompt)\n",
    "\n",
    "model.eval()\n",
    "classes = [\"yes\", \"no\"]\n",
    "with torch.inference_mode():\n",
    "    prompts = [img, prompt] \n",
    "    print(model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5))\n",
    "    print(\"Model Answer: \", classes[model.classification_for_eval(prompts, classes)])\n",
    "    \n",
    "print(\"Correct Answer: \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aaf57b-2bd6-4303-89a5-32d00f3d4159",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0e3ab5-e33b-46dc-acab-255f750b9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "transform = cxr_image_transform(resize=512, center_crop_size=480, train=False) \n",
    "dataset_closed = VQA_RADDataset(dataset_path, transform, 'closed')\n",
    "dataset_open = VQA_RADDataset(dataset_path, transform, 'open')\n",
    "\n",
    "print(dataset_closed.get_len())\n",
    "print(dataset_open.get_len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63b9cd-194b-4697-92ad-3ebab23c5a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87c3e7d9-5db9-422f-814e-dab5683c79cf",
   "metadata": {},
   "source": [
    "## Closed dataset: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cc5f0-b75a-4d67-b2f4-22d10dd94b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "right_answers = 0\n",
    "total_answers = 0\n",
    "\n",
    "def get_model_response(prompts):\n",
    "    model_ans_full = model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5)\n",
    "    model_ans = model_ans_full.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    try: \n",
    "        model_ans = model_ans.split()[0] # take only the first word, sometimes model makes a whole sentence\n",
    "        return model_ans\n",
    "    except:\n",
    "        return model_ans\n",
    "\n",
    "for idx in tqdm(dataset_closed):\n",
    "    img, q, ans = idx \n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        prompts = [idx[0], str(\"Question: \" + idx[1] + \" Yes/No answer: \")] \n",
    "        for _ in range(4): # try 5 times to get the correct answer\n",
    "            model_ans = get_model_response(prompts)\n",
    "            if model_ans.lower() == ans.lower():\n",
    "                right_answers += 1\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        total_answers += 1        \n",
    "\n",
    "print(right_answers, '/', total_answers )\n",
    "print((right_answers/total_answers)*100, '% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f8752-7986-4811-bf6f-9ff3f147f3d9",
   "metadata": {},
   "source": [
    "## Open dataset: Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e430b-a86b-4bbf-8dfe-cefa12191abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_metric = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1594bab-593f-4f1d-8160-d3d99fd6099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "predictions=['how are you?']\n",
    "references=['hello how are you?']\n",
    "results = exact_match_metric.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a9eb8-5d79-418a-a63a-48ea054d9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bleu_score = 0\n",
    "total = 0\n",
    "\n",
    "for idx in tqdm(dataset_open):\n",
    "    img, q, ans = idx \n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        prompts = [idx[0], str(\"Question: \" + idx[1] + \" Answer: \")] \n",
    "        model_ans_full = model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5)    \n",
    "        current_bleu_scores = []\n",
    "        for _ in range(4): # try 5 times, get the best score of those 5 times\n",
    "            try:\n",
    "                bleu_score = exact_match_metric.compute(predictions=[model_ans_full], references=[ans]).get('bleu')\n",
    "                current_bleu_scores.append(bleu_score)\n",
    "            except:\n",
    "                pass\n",
    "        if len(current_bleu_scores) > 1:\n",
    "            total_bleu_score += max(current_bleu_scores) # you can also take the average\n",
    "        total += 1\n",
    "        \n",
    "print(total_bleu_score, '/', total)\n",
    "print(\"bleu score: \", total_bleu_score/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
