{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305a9d84-b6ef-4f9f-9602-d0312a70cef7",
   "metadata": {},
   "source": [
    "# Tutorial & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b1a639-9a6b-4695-ab72-417a8b448e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fromage.vqa_dataset import VQA_RADDataset\n",
    "from fromage.model import Fromage, FromageModel\n",
    "from fromage.experiment import Experiment\n",
    "from fromage.data import MIMICDataset, cxr_image_transform\n",
    "from fromage.utils import preprocess_report\n",
    "from evaluate import load # if throws error, please run the following command \"pip instal evaluate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2701cd4-9352-41d9-abc5-5a4467d9e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "ckpt_path = \"../logs/checkpoints/lm_gen_vis_med_mistral_rerun2/last.ckpt\"\n",
    "config_path = \"../config/train-untied.yaml\"\n",
    "dataset_path = \"/kuacc/users/hpc-dtank/datasets/VQA_RAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498bf455-f4f9-442e-a9fe-b693037ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = cxr_image_transform(resize=512, center_crop_size=480, train=False) \n",
    "dataset = VQA_RADDataset(dataset_path, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfcacef-05b2-4d95-b943-589c5b5b6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0667, 0.0667, 0.0667,  ..., 0.1882, 0.1725, 0.1412],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2039, 0.1961, 0.2000],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2235, 0.2157, 0.2235],\n",
       "          ...,\n",
       "          [0.0784, 0.0706, 0.0706,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0784, 0.0902]],\n",
       " \n",
       "         [[0.0667, 0.0667, 0.0667,  ..., 0.1882, 0.1725, 0.1412],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2039, 0.1961, 0.2000],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2235, 0.2157, 0.2235],\n",
       "          ...,\n",
       "          [0.0784, 0.0706, 0.0706,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0784, 0.0902]],\n",
       " \n",
       "         [[0.0667, 0.0667, 0.0667,  ..., 0.1882, 0.1725, 0.1412],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2039, 0.1961, 0.2000],\n",
       "          [0.0667, 0.0667, 0.0667,  ..., 0.2235, 0.2157, 0.2235],\n",
       "          ...,\n",
       "          [0.0784, 0.0706, 0.0706,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0706, 0.0902],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0784, 0.0902]]]),\n",
       " 'Are the lungs normal appearing?',\n",
       " 'No')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # returns image, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5d60bf-809b-4230-810e-becc96bb2bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open (config_path) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "model = Experiment(config)\n",
    "model = model.load_from_checkpoint(ckpt_path)\n",
    "model = model.model.to(device)\n",
    "model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba751d9f-a501-4906-bf43-b0328e8c4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  Question: Are the lungs normal appearing? Answer: \n",
      "Model Answer:   No.\n",
      "\n",
      "Question: Are the lungs normal appearing? Answer:  No.\n",
      "\n",
      "Question: Are the lungs normal appearing? Answer:  No.\n",
      "Correct Answer:  No\n"
     ]
    }
   ],
   "source": [
    "img, question, answer = dataset[0]\n",
    "prompt = str(\"Question: \" + question + \" Answer: \")\n",
    "print(\"Prompt: \", prompt)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    prompts = [img, prompt] \n",
    "    print(\"Model Answer: \", model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5))\n",
    "    \n",
    "print(\"Correct Answer: \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aaf57b-2bd6-4303-89a5-32d00f3d4159",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0e3ab5-e33b-46dc-acab-255f750b9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "transform = cxr_image_transform(resize=512, center_crop_size=480, train=False) \n",
    "dataset_closed = VQA_RADDataset(dataset_path, transform, 'closed')\n",
    "dataset_open = VQA_RADDataset(dataset_path, transform, 'open')\n",
    "\n",
    "print(dataset_closed.get_len())\n",
    "print(dataset_open.get_len())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3e7d9-5db9-422f-814e-dab5683c79cf",
   "metadata": {},
   "source": [
    "## Closed dataset: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2cc5f0-b75a-4d67-b2f4-22d10dd94b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511/511 [08:52<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 / 511\n",
      "26.810176125244617 % correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "right_answers = 0\n",
    "total_answers = 0\n",
    "\n",
    "def get_model_response(prompts):\n",
    "    model_ans_full = model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5)\n",
    "    model_ans = model_ans_full.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    try: \n",
    "        model_ans = model_ans.split()[0] # take only the first word, sometimes model makes a whole sentence\n",
    "        return model_ans\n",
    "    except:\n",
    "        return model_ans\n",
    "\n",
    "for idx in tqdm(dataset_closed):\n",
    "    img, q, ans = idx \n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        prompts = [idx[0], str(\"Question: \" + idx[1] + \" Yes/No answer: \")] \n",
    "        for _ in range(4): # try 5 times to get the correct answer\n",
    "            model_ans = get_model_response(prompts)\n",
    "            if model_ans.lower() == ans.lower():\n",
    "                right_answers += 1\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        total_answers += 1        \n",
    "\n",
    "print(right_answers, '/', total_answers )\n",
    "print((right_answers/total_answers)*100, '% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f8752-7986-4811-bf6f-9ff3f147f3d9",
   "metadata": {},
   "source": [
    "## Open dataset: Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c2e430b-a86b-4bbf-8dfe-cefa12191abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_metric = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1594bab-593f-4f1d-8160-d3d99fd6099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.7788007830714049, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 0.7788007830714049, 'length_ratio': 0.8, 'translation_length': 4, 'reference_length': 5}\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "predictions=['how are you?']\n",
    "references=['hello how are you?']\n",
    "results = exact_match_metric.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e00a9eb8-5d79-418a-a63a-48ea054d9ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283/283 [06:55<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.161692143534558 / 283\n",
      "bleu score:  0.0005713503305108057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_bleu_score = 0\n",
    "total = 0\n",
    "\n",
    "for idx in tqdm(dataset_open):\n",
    "    img, q, ans = idx \n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        prompts = [idx[0], str(\"Question: \" + idx[1] + \" Answer: \")] \n",
    "        model_ans_full = model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5)    \n",
    "        current_bleu_scores = []\n",
    "        for _ in range(4): # try 5 times, get the best score of those 5 times\n",
    "            try:\n",
    "                bleu_score = exact_match_metric.compute(predictions=[model_ans_full], references=[ans]).get('bleu')\n",
    "                current_bleu_scores.append(bleu_score)\n",
    "            except:\n",
    "                pass\n",
    "        if len(current_bleu_scores) > 1:\n",
    "            total_bleu_score += max(current_bleu_scores) # you can also take the average\n",
    "        total += 1\n",
    "        \n",
    "print(total_bleu_score, '/', total)\n",
    "print(\"bleu score: \", total_bleu_score/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
