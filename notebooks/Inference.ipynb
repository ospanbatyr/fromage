{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6cc17c5-72cd-4363-804c-6f8f49439e30",
   "metadata": {},
   "source": [
    "# FromageModel Inference Notebook \n",
    "## 0. Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb83e8b-c262-4d9c-9e3f-0bd120a855b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcccc4e0-e12f-44a0-881c-e394f71a18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../fromage')\n",
    "from model import Fromage, FromageModel\n",
    "from experiment import Experiment\n",
    "from data import MIMICDataset, cxr_image_transform\n",
    "from utils import preprocess_report\n",
    "\n",
    "# from fromage.model import Fromage, FromageModel \n",
    "# from fromage.experiment import Experiment\n",
    "# from fromage.data import MIMICDataset, COCODataset, cxr_image_transform, coco_image_transform\n",
    "# from fromage.utils import preprocess_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf385c32-df2e-4387-b559-1b3b68b8e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../logs/checkpoints/untied_test/last.ckpt\"\n",
    "config_path = \"../config/train-untied.yaml\"\n",
    "dataset_path = \"../data/MIMIC_JPG.tsv\"\n",
    "img_path = \"/datasets/mimic/cxr-jpg/physionet.org/files/mimic-cxr-jpg/2.0.0/files\"\n",
    "\n",
    "# ckpt_path = osp.join(osp.dirname(os.getcwd()), \"logs/checkpoints/vl_eval_3/last.ckpt\")\n",
    "# config_path = osp.join(osp.dirname(os.getcwd()), \"config/train-vleval-3.yaml\")\n",
    "# dataset_path = osp.join(osp.dirname(os.getcwd()), \"data/MIMIC_JPG_train.tsv\")\n",
    "# img_path = \"/datasets/mimic/cxr-jpg/physionet.org/files/mimic-cxr-jpg/2.0.0/files\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0cb0f-75e8-4469-a9d8-9596996e5bf3",
   "metadata": {},
   "source": [
    "## 1. Set device and config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c167724-cf43-4467-98c0-7a367f99d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open (config_path) as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a9134-7bd1-4101-b040-39210d2c7ec9",
   "metadata": {},
   "source": [
    "## 2. Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc5685f-796e-4417-a0ea-96b886196e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Experiment(config)\n",
    "model = model.load_from_checkpoint(ckpt_path)\n",
    "model = model.model.to(device)\n",
    "model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18750851-7d17-4bf4-929a-23435908caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = cxr_image_transform(resize=512, center_crop_size=480, train=False) \n",
    "dataset = MIMICDataset(dataset_path, img_path, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b987d-499f-46b4-92a9-cf50d0221c95",
   "metadata": {},
   "source": [
    "## 3. Get random example report from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e082e1c-8ce7-4de6-b7e9-3dbea2e4a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=3050x2539 at 0x2B2022A4B940>\n",
      "tensor([[[0.4275, 0.4196, 0.4118,  ..., 0.2314, 0.7765, 0.8235],\n",
      "         [0.4510, 0.4314, 0.4196,  ..., 0.2314, 0.7765, 0.8235],\n",
      "         [0.4118, 0.3922, 0.3725,  ..., 0.1843, 0.7137, 0.8196],\n",
      "         ...,\n",
      "         [0.8431, 0.8392, 0.8431,  ..., 0.2392, 0.2235, 0.2078],\n",
      "         [0.8431, 0.8471, 0.8431,  ..., 0.2471, 0.2314, 0.2157],\n",
      "         [0.8431, 0.8431, 0.8471,  ..., 0.2275, 0.2118, 0.1961]],\n",
      "\n",
      "        [[0.4275, 0.4196, 0.4118,  ..., 0.2314, 0.7765, 0.8235],\n",
      "         [0.4510, 0.4314, 0.4196,  ..., 0.2314, 0.7765, 0.8235],\n",
      "         [0.4118, 0.3922, 0.3725,  ..., 0.1843, 0.7137, 0.8196],\n",
      "         ...,\n",
      "         [0.8431, 0.8392, 0.8431,  ..., 0.2392, 0.2235, 0.2078],\n",
      "         [0.8431, 0.8471, 0.8431,  ..., 0.2471, 0.2314, 0.2157],\n",
      "         [0.8431, 0.8431, 0.8471,  ..., 0.2275, 0.2118, 0.1961]],\n",
      "\n",
      "        [[0.4275, 0.4196, 0.4118,  ..., 0.2314, 0.7765, 0.8235],\n",
      "         [0.4510, 0.4314, 0.4196,  ..., 0.2314, 0.7765, 0.8235],\n",
      "         [0.4118, 0.3922, 0.3725,  ..., 0.1843, 0.7137, 0.8196],\n",
      "         ...,\n",
      "         [0.8431, 0.8392, 0.8431,  ..., 0.2392, 0.2235, 0.2078],\n",
      "         [0.8431, 0.8471, 0.8431,  ..., 0.2471, 0.2314, 0.2157],\n",
      "         [0.8431, 0.8431, 0.8471,  ..., 0.2275, 0.2118, 0.1961]]])\n",
      "AP CHEST 6:11 A.M. ON HISTORY: A yearold man with a flail chest and bilateral chest tubes. IMPRESSION: AP chest compared to : Right lower lobe collapse is new. Small pneumothorax is seen on each side of the chest, increased on the left in addition to the stable or even decreasing paramediastinal component. Trauma board outlines the mediastinal reflection around the cardiac apex and lends increased lucency to the diaphragmatic region. On the right, there may also be anterior pleural air collection, but more evident is the very small volume of pleural air inferolaterally. Orientation of the right pleural tube has gone from oblique upward to nearly horizontal. Left apical pleural tube is unchanged in position. ET tube and right subclavian line are in standard placements and an upper enteric drainage tube passes into a nondistended stomach. There is no apparent increase in displacement of multiple bilateral rib fractures. Dr. was paged at 11:15 am and we discussed the findings by telephone at 11:25am.\n"
     ]
    }
   ],
   "source": [
    "ex_idx = random.randint(0, len(dataset) - 1)\n",
    "ex_img, ex_report = dataset.__getitem__(ex_idx)\n",
    "print(ex_img)\n",
    "print(ex_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826684a8-48d9-41d8-8b5b-7cf999d72f74",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50605bec-6577-4f37-a27d-f63f7cc7438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I don't know.\n",
      "\n",
      "Question: What does the previous image show? Answer:   I don't know.\n",
      "\n",
      "Question: What does\n",
      "tensor([[[0.3843, 0.3725, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3765, 0.3725, 0.3686,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3843, 0.3725, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.9059, 0.8314, 0.6980,  ..., 0.6157, 0.5961, 0.5843],\n",
      "         [0.8863, 0.8118, 0.6980,  ..., 0.6235, 0.6039, 0.5961],\n",
      "         [0.8863, 0.8118, 0.6706,  ..., 0.6275, 0.6118, 0.6118]],\n",
      "\n",
      "        [[0.3843, 0.3725, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3765, 0.3725, 0.3686,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3843, 0.3725, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.9059, 0.8314, 0.6980,  ..., 0.6157, 0.5961, 0.5843],\n",
      "         [0.8863, 0.8118, 0.6980,  ..., 0.6235, 0.6039, 0.5961],\n",
      "         [0.8863, 0.8118, 0.6706,  ..., 0.6275, 0.6118, 0.6118]],\n",
      "\n",
      "        [[0.3843, 0.3725, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3765, 0.3725, 0.3686,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3843, 0.3725, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.9059, 0.8314, 0.6980,  ..., 0.6157, 0.5961, 0.5843],\n",
      "         [0.8863, 0.8118, 0.6980,  ..., 0.6235, 0.6039, 0.5961],\n",
      "         [0.8863, 0.8118, 0.6706,  ..., 0.6275, 0.6118, 0.6118]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    prompts = [ex_img, \"Question: What does the previous image show? Answer: \"] \n",
    "    print(model.generate_for_images_and_texts(prompts, top_p=0.9, temperature=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromage_env_kernel",
   "language": "python",
   "name": "fromage_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
